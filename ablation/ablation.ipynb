{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation: Personality Hassles notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Reading the dataset and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scaler import CustomScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['General_hassles', 'Inner_concerns', 'Financial_concerns', 'Time_Pressures']\n",
    "extension = '.csv'\n",
    "dfs = {}\n",
    "test_dfs = {}\n",
    "for filename in filenames:\n",
    "    df = pd.read_csv(f'../data/category/{filename}.csv')\n",
    "    df = df.sample(frac = 1, random_state = 42)\n",
    "\n",
    "    # df['Hassle'] = LabelEncoder().fit_transform(df['Hassle'])\n",
    "\n",
    "    # scaler_O = MinMaxScaler(feature_range=(10, 50))\n",
    "    # scaler_C = MinMaxScaler(feature_range=(9, 45))\n",
    "    # scaler_E = MinMaxScaler(feature_range=(8, 40))\n",
    "    # scaler_A = MinMaxScaler(feature_range=(9, 45))\n",
    "    # scaler_N = MinMaxScaler(feature_range=(8, 40))\n",
    "\n",
    "    # # Fit and transform specific columns\n",
    "    # df['O'] = scaler_O.fit_transform(df[['O']])\n",
    "    # df['C'] = scaler_C.fit_transform(df[['C']])\n",
    "    # df['E'] = scaler_E.fit_transform(df[['E']])\n",
    "    # df['A'] = scaler_A.fit_transform(df[['A']])\n",
    "    # df['N'] = scaler_N.fit_transform(df[['N']])\n",
    "    \n",
    "    #drop age and gender for now\n",
    "    df.drop(columns = ['Age', 'Gender'], inplace = True)\n",
    "\n",
    "    dfs[filename] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1 = ColumnTransformer(\n",
    "    [\n",
    "        ('oScaler', CustomScaler(data_range = [10, 50]), ['O']),\n",
    "        ('cScaler', CustomScaler(data_range = [9, 45]), ['C']),\n",
    "        ('eScaler', CustomScaler(data_range = [8, 40]), ['E']),\n",
    "        ('aScaler', CustomScaler(data_range = [9, 45]), ['A']),\n",
    "        ('nScaler', CustomScaler(data_range = [8, 40]), ['N']),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function dynamically creates a columnt ransformer object and sets in on the piepline\n",
    "\n",
    "# Takes in the array of columns and pipe\n",
    "def create_column_transformer(cols, pipe):\n",
    "    scaler_list = []\n",
    "    for col in cols:\n",
    "        if(col == 'O'):\n",
    "            scaler = ('oScaler', CustomScaler(data_range = [10, 50]), ['O'])\n",
    "        elif(col == 'C'):\n",
    "            scaler = ('cScaler', CustomScaler(data_range = [9, 45]), ['C'])\n",
    "        elif(col == 'E'):\n",
    "            scaler = ('eScaler', CustomScaler(data_range = [8, 40]), ['E'])\n",
    "        elif(col == 'A'):\n",
    "            scaler = ('aScaler', CustomScaler(data_range = [9, 45]), ['A'])\n",
    "        elif(col == 'N'):\n",
    "            scaler = ('nScaler', CustomScaler(data_range = [8, 40]), ['N'])\n",
    "        else:\n",
    "            return ValueError;\n",
    "        scaler_list.append(scaler)\n",
    "    \n",
    "    ct = ColumnTransformer(transformers = scaler_list)\n",
    "\n",
    "    pipe.steps[0] = ('transformer', ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct2 = ColumnTransformer(\n",
    "    [\n",
    "        ('encoder', LabelEncoder(), ['Hassle'])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Model and Hyperparameters Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR, NuSVR, LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor, BaggingRegressor, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "elasticnet = ElasticNet()\n",
    "\n",
    "svr = SVR(verbose = 0)\n",
    "nusvr = NuSVR(verbose = 0)\n",
    "lsvr = LinearSVR(verbose = 0)\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "rfr = RandomForestRegressor( random_state = 42)\n",
    "gbr = GradientBoostingRegressor( random_state = 42)\n",
    "vr = VotingRegressor(estimators = RandomForestRegressor(random_state = 42))\n",
    "br = BaggingRegressor( random_state = 42)\n",
    "abr = AdaBoostRegressor(random_state = 42)\n",
    "\n",
    "nn = MLPRegressor(random_state = 42, verbose = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Pipleline initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessor1', ct1), ('regressor', ridge)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Hyperparams Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = [\n",
    "    {\n",
    "        'regressor': [linreg]\n",
    "    },\n",
    "    {\n",
    "        'regressor__alpha': [0, 0.5, 1, 2],\n",
    "        'regressor__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "        'regressor__tol': [0.0001, 0.00001, 0.001],\n",
    "        'regressor': [ridge]\n",
    "    },\n",
    "    {\n",
    "        'regressor__alpha': [0, 0.5, 1, 2],\n",
    "        'regressor__tol': [0.0001, 0.00001, 0.001],\n",
    "        'regressor__selection': ['cyclic', 'random'],\n",
    "        'regressor': [lasso]\n",
    "    },\n",
    "    {\n",
    "        'regressor__alpha': [0, 0.5, 1, 2],\n",
    "        'regressor__l1_ratio': [0.5, 0.05, 0.005],\n",
    "        'regressor__tol': [0.0001, 0.00001, 0.001],\n",
    "        'regressor__selection': ['cyclic', 'random'],\n",
    "        'regressor': [elasticnet]\n",
    "    },\n",
    "    # {\n",
    "    #     'regressor__kernel': ['rbf', 'linear', 'poly'],\n",
    "    #     'regressor__degree': [3, 7, 11],\n",
    "    #     'regressor__C': [1.0, 1.5, 0.5],\n",
    "    #     'regressor__epsilon': [0.1, 0.01, 0.001],\n",
    "    #     'regressor': [svr]\n",
    "    # },\n",
    "    # {\n",
    "    #     'regressor__kernel': ['rbf', 'linear', 'poly'],\n",
    "    #     'regressor__degree': [3, 7, 11],\n",
    "    #     'regressor__C': [1.0, 1.5, 0.5],\n",
    "    #     'regressor__nu': [0.01, 0.5, 1],\n",
    "    #     'regressor': [nusvr]\n",
    "    # },\n",
    "    # {\n",
    "    #     'regressor__epsilon': [0.0, 0.5, 0.05],\n",
    "    #     'regressor__C': [1.0, 0.5, 1.5],\n",
    "    #     'regressor__tol': [0.0001, 0.00001, 0.001],\n",
    "    #     'regressor__loss': ['epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    #     'regressor': [lsvr]\n",
    "    # },\n",
    "    {\n",
    "        'regressor__criterion': ['squared_error', 'poisson', 'friedman_mse', 'absolute_error'],\n",
    "        'regressor__splitter': ['best', 'random'],\n",
    "        'regressor__max_depth': [4, 8, 12],\n",
    "        'regressor__min_samples_split': [4, 8, 12],\n",
    "        'regressor': [dt]\n",
    "    },\n",
    "    {\n",
    "        'regressor__n_estimators': [10, 15, 20, 25, 45, 55, 75, 100, 125],\n",
    "        'regressor__criterion': ['mse', 'mae', 'friedman_mse', 'poisson'],\n",
    "        'regressor__max_depth': [4, 5, 8, 12],\n",
    "        'regressor__min_samples_split': [4, 8, 12],\n",
    "        'regressor__bootstrap': [True, False],\n",
    "        'regressor': [rfr]\n",
    "    },\n",
    "    {\n",
    "        'regressor__n_estimators': [10, 15, 20, 25, 45, 55, 75, 100, 125],\n",
    "        'regressor__max_depth': [4, 8, 12],\n",
    "        'regressor__min_samples_split': [4, 8, 12],\n",
    "        'regressor__learning_rate': [1.0, 0.1, 0.01],\n",
    "        'regressor__loss': ['ls', 'lad', 'huber', 'quantile'],\n",
    "        'regressor': [gbr]\n",
    "    },\n",
    "    {\n",
    "        'regressor__base_estimator': [\n",
    "            DecisionTreeRegressor(random_state = 42, max_depth = 5), \n",
    "            DecisionTreeRegressor(random_state = 42, max_depth = 8), \n",
    "            DecisionTreeRegressor(random_state = 42, max_depth = 12), \n",
    "            RandomForestRegressor(random_state = 42,  n_estimators = 10),\n",
    "            RandomForestRegressor(random_state = 42,  n_estimators = 15),\n",
    "            RandomForestRegressor(random_state = 42,  n_estimators = 20),\n",
    "            ],\n",
    "        'regressor__n_estimators': [10, 20, 5],\n",
    "        'regressor__bootstrap': [True, False],\n",
    "        'regressor': [br]\n",
    "    },\n",
    "    {\n",
    "        'regressor__base_estimator': [\n",
    "            DecisionTreeRegressor(random_state = 42, max_depth = 5), \n",
    "            DecisionTreeRegressor(random_state = 42, max_depth = 8), \n",
    "            DecisionTreeRegressor(random_state = 42, max_depth = 12), \n",
    "            RandomForestRegressor(random_state = 42, n_estimators = 10), \n",
    "            RandomForestRegressor(random_state = 42, n_estimators = 15), \n",
    "            RandomForestRegressor(random_state = 42, n_estimators = 20), \n",
    "            ],\n",
    "        'regressor__n_estimators': [25, 50, 75],\n",
    "        'regressor__learning_rate': [1.0, 0.1, 0.05],\n",
    "        'regressor__loss': ['linear', 'square', 'exponential'],\n",
    "        'regressor': [abr]\n",
    "    },\n",
    "    {\n",
    "        'regressor__hidden_layer_sizes' : [(20, 20, 20, 20, 20), (15, 15, 15, 15, 15, 15, 15), (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)],\n",
    "        'regressor__alpha': [0.0001, 0.001, 0.00001],\n",
    "        'regressor__learning_rate_init' : [0.0001, 0.001, 0.01],\n",
    "        'regressor__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "        'regressor__solver' : ['adam', 'sgd', 'lbfgs'],\n",
    "        'regressor__activation' : ['relu', 'tanh'],\n",
    "        'regressor': [nn]\n",
    "    },\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Model Training and Prediction\n",
    "\n",
    "PIPELINE: Iterate through each df -> Iterate through each possible combination of OCEAN -> initialize a grid search -> train models -> get predictions -> store subset, r2 scores and best model in an array -> after each iteration of df -> get the highest r2 value in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    426\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 427\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1145\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m-> 1145\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:638\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \n\u001b[0;32m    633\u001b[0m \u001b[38;5;124;03mThe expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03maccepted constraints.\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:96\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     91\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m     )\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'criterion' parameter of RandomForestRegressor must be a str among {'squared_error', 'poisson', 'friedman_mse', 'absolute_error'}. Got 'mae' instead.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[354], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Iterate through each model and the hyperparams\u001b[39;00m\n\u001b[0;32m     30\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(pipe, hyperparameters)\n\u001b[1;32m---> 31\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# grid.best_params_\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Get best model and hyperparams\u001b[39;00m\n\u001b[0;32m     35\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:746\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    744\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n\u001b[0;32m    745\u001b[0m                 train_scores \u001b[38;5;241m=\u001b[39m error_score\n\u001b[1;32m--> 746\u001b[0m     result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mformat_exc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:184\u001b[0m, in \u001b[0;36mformat_exc\u001b[1;34m(limit, chain)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_exc\u001b[39m(limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, chain\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    183\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Like print_exc() but return a string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mformat_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchain\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:139\u001b[0m, in \u001b[0;36mformat_exception\u001b[1;34m(exc, value, tb, limit, chain)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Format a stack trace and the exception information.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03mThe arguments have the same meaning as the corresponding arguments\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03mprinted as does print_exception().\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m value, tb \u001b[38;5;241m=\u001b[39m _parse_value_tb(exc, value, tb)\n\u001b[1;32m--> 139\u001b[0m te \u001b[38;5;241m=\u001b[39m \u001b[43mTracebackException\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(te\u001b[38;5;241m.\u001b[39mformat(chain\u001b[38;5;241m=\u001b[39mchain))\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:728\u001b[0m, in \u001b[0;36mTracebackException.__init__\u001b[1;34m(self, exc_type, exc_value, exc_traceback, limit, lookup_lines, capture_locals, compact, max_group_width, max_group_depth, _seen)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_group_width \u001b[38;5;241m=\u001b[39m max_group_width\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_group_depth \u001b[38;5;241m=\u001b[39m max_group_depth\n\u001b[1;32m--> 728\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_from_extended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_walk_tb_with_full_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_traceback\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlookup_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_locals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type \u001b[38;5;241m=\u001b[39m exc_type\n\u001b[0;32m    733\u001b[0m \u001b[38;5;66;03m# Capture now to permit freeing resources: only complication is in the\u001b[39;00m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;66;03m# unofficial API _format_final_exc_line\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:429\u001b[0m, in \u001b[0;36mStackSummary._extract_from_extended_frame_gen\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    425\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    426\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals,\n\u001b[0;32m    427\u001b[0m         end_lineno\u001b[38;5;241m=\u001b[39mend_lineno, colno\u001b[38;5;241m=\u001b[39mcolno, end_colno\u001b[38;5;241m=\u001b[39mend_colno))\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m--> 429\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(fullname)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for df_name, df in dfs.items():\n",
    "    # Trying ablation study for General hassles\n",
    "    feature_columns = dfs['General_hassles'].columns[:-2]\n",
    "\n",
    "    # Initialize a subset, r2 scores and models array\n",
    "    subsets = []\n",
    "    r2scores = []\n",
    "    models = []\n",
    "    params = []\n",
    "\n",
    "\n",
    "    # Iterate through each possible subset\n",
    "    for L in range(1, len(feature_columns) + 1):\n",
    "        for subset in itertools.combinations(feature_columns, L):\n",
    "            selected_features = list(subset)\n",
    "\n",
    "            # Initialize X and y\n",
    "            X = df[selected_features]\n",
    "            X['Hassle'] = df['Hassle']\n",
    "            y = df.iloc[:, -1]\n",
    "\n",
    "            # Train test split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "            # Change the columns in column transformer\n",
    "            create_column_transformer(subset, pipe)\n",
    "\n",
    "            # Iterate through each model and the hyperparams\n",
    "            grid = GridSearchCV(pipe, hyperparameters)\n",
    "            grid.fit(X_train, y_train)\n",
    "            # grid.best_params_\n",
    "\n",
    "            # Get best model and hyperparams\n",
    "            best_model = grid.best_estimator_\n",
    "            best_params = grid.best_params_\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = best_model.predict(X_test)\n",
    "\n",
    "            # Get r2 score\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            #Save subsets, r2score, params and model\n",
    "            subsets.append(subset)\n",
    "            r2scores.append(r2)\n",
    "            params.append(best_params)\n",
    "            models.append(best_model)\n",
    "\n",
    "    # Get the index of the highest r2 score on the current dataset\n",
    "    highest_r2_index = r2scores.index(max(r2scores))\n",
    "\n",
    "    # Get the corresponding subset, params and model\n",
    "    corr_subset = subsets[highest_r2_index]\n",
    "    corr_params = params[highest_r2_index]\n",
    "    corr_model = models[highest_r2_index]\n",
    "\n",
    "    # Show the results\n",
    "    print(df_name)\n",
    "    print(\"Subset: \", corr_subset)\n",
    "    print(\"R2 score: \", max(r2scores))\n",
    "    display(corr_model)\n",
    "\n",
    "    # Define directory where params and model will be saved\n",
    "    params_directory = Path('models/specs/')\n",
    "    model_directory = Path('models/model/')\n",
    "\n",
    "    # Get model name\n",
    "    name = type(corr_model).__name__\n",
    "\n",
    "    # Generate file\n",
    "    params_file = params_directory / f\"{df_name}_{name}_hyperparams.pkl\"\n",
    "    model_file = model_directory / f\"{df_name}_{name}_model.pkl\"\n",
    "\n",
    "    # Save hyperparams\n",
    "    with open(params_file, 'wb') as f:\n",
    "        joblib.dump(best_params, f)\n",
    "\n",
    "    # Save Model\n",
    "    with open(model_file, 'wb') as f:\n",
    "        joblib.dump(best_model, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Trying ablation study for General hassles\n",
    "# feature_columns = dfs['General_hassles'].columns[:-2]\n",
    "\n",
    "# # Initialize a subset, r2 scores and models array\n",
    "# subsets = []\n",
    "# r2scores = []\n",
    "# models = []\n",
    "# params = []\n",
    "\n",
    "# for L in range(1, len(feature_columns) + 1):\n",
    "#     for subset in itertools.combinations(feature_columns, L):\n",
    "#         selected_features = list(subset)\n",
    "\n",
    "#         # Initialize X and y\n",
    "#         X = df[selected_features]\n",
    "#         X['Hassle'] = df['Hassle']\n",
    "#         y = df.iloc[:, -1]\n",
    "\n",
    "#         # Train test split\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#         # Change the columns in column transformer\n",
    "#         create_column_transformer(subset, pipe)\n",
    "\n",
    "#         # Iterate through each model and the hyperparams\n",
    "#         grid = GridSearchCV(pipe, hyperparameters)\n",
    "#         grid.fit(X_train, y_train)\n",
    "#         # grid.best_params_\n",
    "\n",
    "#         # Get best model and hyperparams\n",
    "#         best_model = grid.best_estimator_\n",
    "#         best_params = grid.best_params_\n",
    "\n",
    "#         # Get best model name\n",
    "#         name = type(best_model).__name__\n",
    "\n",
    "#         # Make predictions\n",
    "#         y_pred = best_model.predict(X_test)\n",
    "\n",
    "#         # Get r2 score\n",
    "#         r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "#         #Save subsets, r2score, params and model\n",
    "#         subsets.append(subset)\n",
    "#         r2scores.append(r2)\n",
    "#         params.append(best_params)\n",
    "#         models.append(best_model)\n",
    "\n",
    "# # Get the index of the highest r2 score\n",
    "# highest_r2_index = r2scores.index(max(r2scores))\n",
    "\n",
    "# # Get the corresponding subset, params and model\n",
    "# corr_subset = subsets[highest_r2_index]\n",
    "# corr_params = params[highest_r2_index]\n",
    "# corr_model = models[highest_r2_index]\n",
    "\n",
    "# #Show the results\n",
    "# print(\"Subset: \", corr_subset)\n",
    "# print(\"R2 score: \", max(r2scores))\n",
    "# print(corr_model)\n",
    "\n",
    "# # Define directory where model will be saved\n",
    "\n",
    "\n",
    "# # Generate filename\n",
    "\n",
    "# # Save Model\n",
    "\n",
    "# # Save hyperparams\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
